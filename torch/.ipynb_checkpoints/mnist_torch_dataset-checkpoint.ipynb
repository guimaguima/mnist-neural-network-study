{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6faaff98-cf7e-4d88-bfdd-dccdb6ed6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4334, 0.2502, 0.7687],\n",
      "        [0.1044, 0.6912, 0.6307],\n",
      "        [0.2910, 0.2226, 0.9719],\n",
      "        [0.4136, 0.6988, 0.2441],\n",
      "        [0.6615, 0.5158, 0.6993]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a480442-4fc2-44be-8d9a-ae21cc995284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando na cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Rodando na {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0266a6b5-6a51-40c4-8604-139f7fad3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nsamples = 64\n",
    "test_nsamples = 50\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,batch_size=train_nsamples, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2,batch_size=test_nsamples, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84163228-ef96-4b7d-b145-2ba8e4ad8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import MNIST_NN\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e05c4b-31e7-4856-8151-91841410ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_NN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c5afa8-4e2c-44a9-92b8-07cdd39d004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Imagens (data): torch.Size([64, 1, 28, 28])\n",
      "Rótulos (target): torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(f'Batch {batch_idx + 1}:')\n",
    "    print('Imagens (data):', data.size())\n",
    "    print('Rótulos (target):', target.size())\n",
    "\n",
    "\n",
    "    plt.imshow(data[0].squeeze(), cmap='gray')\n",
    "    plt.title(f'Rótulo: {target[0].item()}')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6777499-ed4c-4304-a544-90976b43c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \n",
      " Loss: 2.3033924102783203 \n",
      " Acurracy: 6.666666740784422e-05\n",
      "Train Epoch: 10 \n",
      " Loss: 2.278550863265991 \n",
      " Acurracy: 0.003650000086054206\n",
      "Train Epoch: 20 \n",
      " Loss: 2.231501817703247 \n",
      " Acurracy: 0.00860000029206276\n",
      "Train Epoch: 30 \n",
      " Loss: 2.072561502456665 \n",
      " Acurracy: 0.014683333225548267\n",
      "Train Epoch: 40 \n",
      " Loss: 2.0034608840942383 \n",
      " Acurracy: 0.020800000056624413\n",
      "Train Epoch: 50 \n",
      " Loss: 1.854735255241394 \n",
      " Acurracy: 0.02798333391547203\n",
      "Train Epoch: 60 \n",
      " Loss: 1.7837111949920654 \n",
      " Acurracy: 0.03505000099539757\n",
      "Train Epoch: 70 \n",
      " Loss: 1.7252466678619385 \n",
      " Acurracy: 0.04374999925494194\n",
      "Train Epoch: 80 \n",
      " Loss: 1.6800565719604492 \n",
      " Acurracy: 0.052549999207258224\n",
      "Train Epoch: 90 \n",
      " Loss: 1.6836482286453247 \n",
      " Acurracy: 0.06134999915957451\n",
      "Train Epoch: 100 \n",
      " Loss: 1.6784676313400269 \n",
      " Acurracy: 0.070333331823349\n",
      "Train Epoch: 110 \n",
      " Loss: 1.6242128610610962 \n",
      " Acurracy: 0.07973333448171616\n",
      "Train Epoch: 120 \n",
      " Loss: 1.6821039915084839 \n",
      " Acurracy: 0.08869999647140503\n",
      "Train Epoch: 130 \n",
      " Loss: 1.56852388381958 \n",
      " Acurracy: 0.097933329641819\n",
      "Train Epoch: 140 \n",
      " Loss: 1.6335569620132446 \n",
      " Acurracy: 0.10713333636522293\n",
      "Train Epoch: 150 \n",
      " Loss: 1.5867230892181396 \n",
      " Acurracy: 0.116716668009758\n",
      "Train Epoch: 160 \n",
      " Loss: 1.602137565612793 \n",
      " Acurracy: 0.12600000202655792\n",
      "Train Epoch: 170 \n",
      " Loss: 1.6217765808105469 \n",
      " Acurracy: 0.13519999384880066\n",
      "Train Epoch: 180 \n",
      " Loss: 1.5398157835006714 \n",
      " Acurracy: 0.1446000039577484\n",
      "Train Epoch: 190 \n",
      " Loss: 1.601549506187439 \n",
      " Acurracy: 0.1538500040769577\n",
      "Train Epoch: 200 \n",
      " Loss: 1.6336361169815063 \n",
      " Acurracy: 0.16345000267028809\n",
      "Train Epoch: 210 \n",
      " Loss: 1.5995372533798218 \n",
      " Acurracy: 0.17301666736602783\n",
      "Train Epoch: 220 \n",
      " Loss: 1.5511548519134521 \n",
      " Acurracy: 0.18246667087078094\n",
      "Train Epoch: 230 \n",
      " Loss: 1.575657844543457 \n",
      " Acurracy: 0.19193333387374878\n",
      "Train Epoch: 240 \n",
      " Loss: 1.6579420566558838 \n",
      " Acurracy: 0.20155000686645508\n",
      "Train Epoch: 250 \n",
      " Loss: 1.5254698991775513 \n",
      " Acurracy: 0.21115000545978546\n",
      "Train Epoch: 260 \n",
      " Loss: 1.6472163200378418 \n",
      " Acurracy: 0.22073332965373993\n",
      "Train Epoch: 270 \n",
      " Loss: 1.5426567792892456 \n",
      " Acurracy: 0.23038333654403687\n",
      "Train Epoch: 280 \n",
      " Loss: 1.5668432712554932 \n",
      " Acurracy: 0.24005000293254852\n",
      "Train Epoch: 290 \n",
      " Loss: 1.6098512411117554 \n",
      " Acurracy: 0.24961666762828827\n",
      "Train Epoch: 300 \n",
      " Loss: 1.5585883855819702 \n",
      " Acurracy: 0.25921666622161865\n",
      "Train Epoch: 310 \n",
      " Loss: 1.5842920541763306 \n",
      " Acurracy: 0.2690500020980835\n",
      "Train Epoch: 320 \n",
      " Loss: 1.5521363019943237 \n",
      " Acurracy: 0.2785666584968567\n",
      "Train Epoch: 330 \n",
      " Loss: 1.5243020057678223 \n",
      " Acurracy: 0.2883666753768921\n",
      "Train Epoch: 340 \n",
      " Loss: 1.5860427618026733 \n",
      " Acurracy: 0.29776665568351746\n",
      "Train Epoch: 350 \n",
      " Loss: 1.55645751953125 \n",
      " Acurracy: 0.307533323764801\n",
      "Train Epoch: 360 \n",
      " Loss: 1.6281965970993042 \n",
      " Acurracy: 0.31681665778160095\n",
      "Train Epoch: 370 \n",
      " Loss: 1.587631106376648 \n",
      " Acurracy: 0.32641667127609253\n",
      "Train Epoch: 380 \n",
      " Loss: 1.5667201280593872 \n",
      " Acurracy: 0.3359333276748657\n",
      "Train Epoch: 390 \n",
      " Loss: 1.5648094415664673 \n",
      " Acurracy: 0.3454333245754242\n",
      "Train Epoch: 400 \n",
      " Loss: 1.639508605003357 \n",
      " Acurracy: 0.35499998927116394\n",
      "Train Epoch: 410 \n",
      " Loss: 1.5777753591537476 \n",
      " Acurracy: 0.36461666226387024\n",
      "Train Epoch: 420 \n",
      " Loss: 1.5518949031829834 \n",
      " Acurracy: 0.3742833435535431\n",
      "Train Epoch: 430 \n",
      " Loss: 1.6016201972961426 \n",
      " Acurracy: 0.38376668095588684\n",
      "Train Epoch: 440 \n",
      " Loss: 1.5554124116897583 \n",
      " Acurracy: 0.3935833275318146\n",
      "Train Epoch: 450 \n",
      " Loss: 1.5068721771240234 \n",
      " Acurracy: 0.4034166634082794\n",
      "Train Epoch: 460 \n",
      " Loss: 1.5748435258865356 \n",
      " Acurracy: 0.4132166802883148\n",
      "Train Epoch: 470 \n",
      " Loss: 1.5233757495880127 \n",
      " Acurracy: 0.42293334007263184\n",
      "Train Epoch: 480 \n",
      " Loss: 1.5595757961273193 \n",
      " Acurracy: 0.4325833320617676\n",
      "Train Epoch: 490 \n",
      " Loss: 1.6440868377685547 \n",
      " Acurracy: 0.44209998846054077\n",
      "Train Epoch: 500 \n",
      " Loss: 1.5384410619735718 \n",
      " Acurracy: 0.45161667466163635\n",
      "Train Epoch: 510 \n",
      " Loss: 1.5848948955535889 \n",
      " Acurracy: 0.4611999988555908\n",
      "Train Epoch: 520 \n",
      " Loss: 1.6178505420684814 \n",
      " Acurracy: 0.47091665863990784\n",
      "Train Epoch: 530 \n",
      " Loss: 1.545400619506836 \n",
      " Acurracy: 0.4807666540145874\n",
      "Train Epoch: 540 \n",
      " Loss: 1.603471279144287 \n",
      " Acurracy: 0.4902999997138977\n",
      "Train Epoch: 550 \n",
      " Loss: 1.5443824529647827 \n",
      " Acurracy: 0.5000166893005371\n",
      "Train Epoch: 560 \n",
      " Loss: 1.529728651046753 \n",
      " Acurracy: 0.5099999904632568\n",
      "Train Epoch: 570 \n",
      " Loss: 1.5121287107467651 \n",
      " Acurracy: 0.5198000073432922\n",
      "Train Epoch: 580 \n",
      " Loss: 1.5854401588439941 \n",
      " Acurracy: 0.529449999332428\n",
      "Train Epoch: 590 \n",
      " Loss: 1.5698704719543457 \n",
      " Acurracy: 0.5391333103179932\n",
      "Train Epoch: 600 \n",
      " Loss: 1.6158018112182617 \n",
      " Acurracy: 0.5489333271980286\n",
      "Train Epoch: 610 \n",
      " Loss: 1.5228246450424194 \n",
      " Acurracy: 0.5587499737739563\n",
      "Train Epoch: 620 \n",
      " Loss: 1.5623799562454224 \n",
      " Acurracy: 0.5684666633605957\n",
      "Train Epoch: 630 \n",
      " Loss: 1.5647802352905273 \n",
      " Acurracy: 0.5779833197593689\n",
      "Train Epoch: 640 \n",
      " Loss: 1.5718140602111816 \n",
      " Acurracy: 0.5876333117485046\n",
      "Train Epoch: 650 \n",
      " Loss: 1.490236759185791 \n",
      " Acurracy: 0.597516655921936\n",
      "Train Epoch: 660 \n",
      " Loss: 1.5545638799667358 \n",
      " Acurracy: 0.6072166562080383\n",
      "Train Epoch: 670 \n",
      " Loss: 1.5887072086334229 \n",
      " Acurracy: 0.6169666647911072\n",
      "Train Epoch: 680 \n",
      " Loss: 1.5038905143737793 \n",
      " Acurracy: 0.6268166899681091\n",
      "Train Epoch: 690 \n",
      " Loss: 1.5659644603729248 \n",
      " Acurracy: 0.6366000175476074\n",
      "Train Epoch: 700 \n",
      " Loss: 1.5410852432250977 \n",
      " Acurracy: 0.6463500261306763\n",
      "Train Epoch: 710 \n",
      " Loss: 1.5393397808074951 \n",
      " Acurracy: 0.6561999917030334\n",
      "Train Epoch: 720 \n",
      " Loss: 1.5677807331085205 \n",
      " Acurracy: 0.6659500002861023\n",
      "Train Epoch: 730 \n",
      " Loss: 1.580479621887207 \n",
      " Acurracy: 0.6756166815757751\n",
      "Train Epoch: 740 \n",
      " Loss: 1.5451817512512207 \n",
      " Acurracy: 0.6854333281517029\n",
      "Train Epoch: 750 \n",
      " Loss: 1.598871111869812 \n",
      " Acurracy: 0.6948999762535095\n",
      "Train Epoch: 760 \n",
      " Loss: 1.5489678382873535 \n",
      " Acurracy: 0.7046499848365784\n",
      "Train Epoch: 770 \n",
      " Loss: 1.540579915046692 \n",
      " Acurracy: 0.7143499851226807\n",
      "Train Epoch: 780 \n",
      " Loss: 1.5291059017181396 \n",
      " Acurracy: 0.7242666482925415\n",
      "Train Epoch: 790 \n",
      " Loss: 1.5359859466552734 \n",
      " Acurracy: 0.7343833446502686\n",
      "Train Epoch: 800 \n",
      " Loss: 1.5615967512130737 \n",
      " Acurracy: 0.7442666888237\n",
      "Train Epoch: 810 \n",
      " Loss: 1.5358210802078247 \n",
      " Acurracy: 0.7540666460990906\n",
      "Train Epoch: 820 \n",
      " Loss: 1.551142930984497 \n",
      " Acurracy: 0.7640166878700256\n",
      "Train Epoch: 830 \n",
      " Loss: 1.489608883857727 \n",
      " Acurracy: 0.7738833427429199\n",
      "Train Epoch: 840 \n",
      " Loss: 1.5681953430175781 \n",
      " Acurracy: 0.7837333083152771\n",
      "Train Epoch: 850 \n",
      " Loss: 1.5464129447937012 \n",
      " Acurracy: 0.7938666939735413\n",
      "Train Epoch: 860 \n",
      " Loss: 1.5820850133895874 \n",
      " Acurracy: 0.8036166429519653\n",
      "Train Epoch: 870 \n",
      " Loss: 1.529771327972412 \n",
      " Acurracy: 0.8134999871253967\n",
      "Train Epoch: 880 \n",
      " Loss: 1.598118782043457 \n",
      " Acurracy: 0.8235333561897278\n",
      "Train Epoch: 890 \n",
      " Loss: 1.4985696077346802 \n",
      " Acurracy: 0.833466649055481\n",
      "Train Epoch: 900 \n",
      " Loss: 1.5418092012405396 \n",
      " Acurracy: 0.8432333469390869\n",
      "Train Epoch: 910 \n",
      " Loss: 1.5371233224868774 \n",
      " Acurracy: 0.8531000018119812\n",
      "Train Epoch: 920 \n",
      " Loss: 1.6032410860061646 \n",
      " Acurracy: 0.8626833558082581\n",
      "Train Epoch: 930 \n",
      " Loss: 1.531134009361267 \n",
      " Acurracy: 0.8724833130836487\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train(model,device,train_loader,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6229fb-a10c-437f-b67f-56bfa6a9ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.030722907531261445 \n",
      " Acurracy 0.9308\n"
     ]
    }
   ],
   "source": [
    "test(model,device,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
